{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inputing csv file as the data, skip this block if the dataframe is already loaded\n",
    "df = pd.read_csv('df_data_filter.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "wq = ['BOD', 'AmNi', 'Chla', 'DO', 'Ecoli', 'FC', 'NitraNi', 'NitriNi', 'OrPh', 'pH', 'Sal', 'SDD', 'Si', 'SS', 'Temp', 'TIN', 'TKN', 'ToNi', 'ToPh', 'Tur', 'UnAm', 'VSS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train and test datasets\n",
    "\n",
    "df_train = df[df['Image_Year'] <= 2019].drop(columns=['Image_Year']).copy()\n",
    "df_test = df[df['Image_Year'] == 2020].drop(columns=['Image_Year']).copy()\n",
    "X_train = df_train.drop(columns = wq)\n",
    "X_test = df_test.drop(columns = wq)\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler.set_output(transform='pandas')\n",
    "\n",
    "# Transform the data (centering and scaling features)\n",
    "df_train_scaled = std_scaler.fit_transform(df_train)\n",
    "X_train_scaled = std_scaler.fit_transform(X_train)\n",
    "X_test_scaled = std_scaler.fit_transform(X_test)\n",
    "\n",
    "df_scaled = std_scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_TimeSeries(df, wq_name, first, seed, n_splits=5, epochs=50, batch_size=32):\n",
    "    \n",
    "    print(wq_name, \"Started\")\n",
    "    print(\"nvar\", first)\n",
    "    print(\"Seed\", seed)\n",
    "    \n",
    "    # Define the TimeSeriesSplit\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    \n",
    "    LSTM_results = []\n",
    "\n",
    "    for train_index, test_index in tscv.split(df_scaled):\n",
    "        df_train, df_test = df_scaled.iloc[train_index], df_scaled.iloc[test_index]\n",
    "        X_train, X_test = df_train.drop(columns=[wq_name]), df_test.drop(columns=[wq_name])\n",
    "        Y_train, Y_test = df_train[wq_name], df_test[wq_name]\n",
    "        print(\"\\n--------------------------------------\")\n",
    "        print(f'Training split: {train_index[0]} to {train_index[-1]}, Testing split: {test_index[0]} to {test_index[-1]}')\n",
    "        \n",
    "        # Correlation-based feature selection\n",
    "        c = df_train.corr().copy()\n",
    "        c = c[wq_name][22:113]\n",
    "        c = abs(c).sort_values(ascending=False)[0:first]\n",
    "        var = c.index.tolist()\n",
    "        \n",
    "        X_train2 = X_train[var]\n",
    "        X_test2 = X_test[var]\n",
    "        \n",
    "        # Reshape data for LSTM [samples, time steps, features]\n",
    "        X_train2 = np.expand_dims(X_train2, axis=1)\n",
    "        X_test2 = np.expand_dims(X_test2, axis=1)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, activation='relu', input_shape=(X_train2.shape[1], X_train2.shape[2])))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        # Early stopping to avoid overfitting\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "\n",
    "        history = model.fit(X_train2, Y_train, epochs=epochs, batch_size=batch_size, \n",
    "                            validation_split=0.2, verbose=1, callbacks=[es])\n",
    "        \n",
    "        # Evaluate model on training data\n",
    "        Y_train_pred = model.predict(X_train2).flatten()\n",
    "        Y_train_pred[Y_train_pred < 0] = 0.0\n",
    "        r_squared = model.evaluate(X_train2, Y_train, verbose=0)\n",
    "        rmse = mean_squared_error(Y_train, Y_train_pred, squared=False)\n",
    "        mae = mean_absolute_error(Y_train, Y_train_pred)\n",
    "        smape = np.mean(2 * (np.abs(Y_train_pred - Y_train)) / (np.abs(Y_train) + np.abs(Y_train_pred)))\n",
    "        \n",
    "        print(f'R2: {r_squared}, RMSE: {rmse}, MAE: {mae}, SMAPE: {smape}')\n",
    "\n",
    "        # Test model on testing data\n",
    "        Y_test_pred = model.predict(X_test2).flatten()\n",
    "        Y_test_pred[Y_test_pred < 0] = 0.0\n",
    "        r_squared_test = model.evaluate(X_test2, Y_test, verbose=0)\n",
    "        rmse_test = mean_squared_error(Y_test, Y_test_pred, squared=False)\n",
    "        mae_test = mean_absolute_error(Y_test, Y_test_pred)\n",
    "        smape_test = np.mean(2 * (np.abs(Y_test_pred - Y_test)) / (np.abs(Y_test) + np.abs(Y_test_pred)))\n",
    "        \n",
    "        print(f'R2 Test: {r_squared_test}, RMSE Test: {rmse_test}, MAE Test: {mae_test}, SMAPE Test: {smape_test}')\n",
    "\n",
    "        LSTM_df = pd.DataFrame({\n",
    "            'WQ': [wq_name], 'nvar': [len(var)], 'var': [var], 'random_state': [seed],\n",
    "            'r2': [r_squared], 'rmse': [rmse], 'mae': [mae], 'smape': [smape],\n",
    "            'r2_test': [r_squared_test], 'rmse_test': [rmse_test], 'mae_test': [mae_test], 'smape_test': [smape_test]\n",
    "        })\n",
    "\n",
    "        LSTM_results.append(LSTM_df)\n",
    "        print(\"--------------------------------------\\n\")\n",
    "        \n",
    "\n",
    "    print(wq_name, \"Finished\")\n",
    "    \n",
    "    # Combine all results into a single DataFrame\n",
    "    return pd.concat(LSTM_results, ignore_index=True)\n",
    "\n",
    "wq = ['Chla', 'SS', 'Tur']\n",
    "LSTM_result_list = [LSTM_TimeSeries(df_scaled, wq_name=value, first=f, seed=1) for value in wq for f in range(4, 13)]\n",
    "LSTM_result = pd.concat(LSTM_result_list)\n",
    "\n",
    "LSTM_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_result.to_csv(\"LSTM_result_list.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
